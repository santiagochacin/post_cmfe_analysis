{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python analysis of output from MATLAB CNMF-E implementation\n",
    "\n",
    "Analyze tif stacks using `batch_cnmf.py` and then open the resultant analysis products using a workflow like the one shown below.\n",
    "\n",
    "These results were generated using the command:\n",
    "```\n",
    "python batch_cnmf.py '/home/deisseroth/Data/Test2/'\n",
    "```\n",
    "\n",
    "Contours are plotted using a function from Caiman: https://github.com/flatironinstitute/CaImAn.\n",
    "\n",
    "Generally, Caiman analysis functions can be mostly used with results generated from `batch_cnmf.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.sparse as sparse\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "\n",
    "import python_utils as utils\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First load up all `out.mat` files that CNMF-E generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What was the base directory where we ran the batch analysis?\n",
    "base_path = '/Volumes/My_Passport/cnmfe_analysis_files/GRIN013/H11_M46_S9_04112019'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load up all processed files found in base directory\n",
    "results_files = []  # Loaded mat files containing CNMF-E output\n",
    "results_names = []  # Name of folders where results were saved\n",
    "for root, dirs, files in os.walk(base_path):\n",
    "        if 'out.mat' in files:\n",
    "            idx = len(base_path.split(os.sep))\n",
    "            name = root.split(os.sep)[idx]\n",
    "            results_files.append(sio.loadmat(root + os.sep + 'out.mat'))\n",
    "            results_names.append(name)\n",
    "            print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Then let's plot all the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of our results are stored in the `out.mat` file that we loaded above into a dictionary stored within a list called `results_files`.\n",
    "\n",
    "The most relevant keys in each `results` dictionary are:\n",
    "- `A` -- Sparse matrix of spatial filters (e.g. for use plotting contours below)\n",
    "- `S` -- Deconvolved spike trains estimated for each neuron\n",
    "- `C` -- Denoised calcium signals computed for each neuron\n",
    "- `C_raw` -- Raw calcium signals extracted from each neuron\n",
    "- `file` -- File that was analyzed to generate this results file\n",
    "\n",
    "Now that we've loaded it we can look at the results of our analysis as illustrated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the path of the first loaded results file\n",
    "print(results_names[0], results_files[0]['file'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neurons to plot\n",
    "neurons_idx = 10\n",
    "\n",
    "# Frames to plot\n",
    "frames = 2000\n",
    "\n",
    "# Make a plot showing some time series traces\n",
    "for name, results in zip(results_names, results_files):\n",
    "        plt.figure(figsize=(15,10))\n",
    "        plt.title(name)\n",
    "        plt.axis('off')\n",
    "        \n",
    "        S = np.array(results['S'].todense())  # Inferred spikes\n",
    "        C = np.array(results['C'])  # Denoised fluorescence\n",
    "        F = np.array(results['C_raw'])  # Raw fluorescence\n",
    "        \n",
    "        for idx in range(np.shape(F)[0]):\n",
    "            plt.plot(utils.normalize(S[idx, :frames], percentile=False) + idx, 'r')\n",
    "            plt.plot(utils.normalize(F[idx, :frames]) + idx, 'k')\n",
    "            plt.plot(utils.normalize(C[idx, :frames]) + idx, 'b')\n",
    "            if idx > neurons_idx:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a plot showing contours from each dataset\n",
    "for name, results in zip(results_names, results_files):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    \n",
    "    # Call contour plotting function from Caiman (with our results from MATLAB!)\n",
    "    coordinates = utils.plot_contours(results['A'].todense(), \n",
    "                                      results['Cn'],\n",
    "                                      display_numbers=False, maxthr=.6,\n",
    "                                      cmap='gray', colors='r')\n",
    "    plt.title(name)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
